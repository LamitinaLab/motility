{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95c72ce",
   "metadata": {},
   "source": [
    "# Notebook 03: Data Archiving for C. elegans Motility Analysis\n",
    "\n",
    "This notebook handles:\n",
    "- Organizing and archiving processed data\n",
    "- Creating comprehensive analysis reports\n",
    "- Archiving raw data with metadata\n",
    "- Generating summary documentation\n",
    "- Preparing data packages for publication/sharing\n",
    "- Timestamped backups of analysis outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d17ff7",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef5050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import json\n",
    "import yaml\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d3ce5",
   "metadata": {},
   "source": [
    "## 2. Configuration and Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33a09fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive session directory: C:\\Users\\MBF\\Motility_analysis\\Data\\Archive\\archive_20260224_164750\n",
      "Timestamp: 20260224_164750\n"
     ]
    }
   ],
   "source": [
    "# Base paths\n",
    "BASE_DIR = Path(r'C:\\Users\\MBF\\Motility_analysis')\n",
    "RAW_DATA_DIR = BASE_DIR / 'Data' / 'Raw'\n",
    "PROCESSED_DATA_DIR = BASE_DIR / 'Data' / 'Processed'\n",
    "ARCHIVE_DIR = BASE_DIR / 'Data' / 'Archive'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "FIGURES_DIR = RESULTS_DIR / 'figures'\n",
    "\n",
    "# Create timestamp for this archiving session\n",
    "TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "ARCHIVE_SESSION_DIR = ARCHIVE_DIR / f'archive_{TIMESTAMP}'\n",
    "\n",
    "# Create archive directories\n",
    "ARCHIVE_SESSION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(ARCHIVE_SESSION_DIR / 'processed_data').mkdir(exist_ok=True)\n",
    "(ARCHIVE_SESSION_DIR / 'results').mkdir(exist_ok=True)\n",
    "(ARCHIVE_SESSION_DIR / 'figures').mkdir(exist_ok=True)\n",
    "(ARCHIVE_SESSION_DIR / 'metadata').mkdir(exist_ok=True)\n",
    "(ARCHIVE_SESSION_DIR / 'raw_data').mkdir(exist_ok=True)\n",
    "(ARCHIVE_SESSION_DIR / 'notebooks').mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Archive session directory: {ARCHIVE_SESSION_DIR}\")\n",
    "print(f\"Timestamp: {TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750bc3f",
   "metadata": {},
   "source": [
    "## 3. Archive Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dcfb642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archiving 3 processed data file(s)...\n",
      "  ✓ Archived: normalized_tracks.csv\n",
      "  ✓ Archived: thrashing_data.csv\n",
      "  ✓ Archived: track_metrics.csv\n",
      "\n",
      "Processed data archived successfully!\n"
     ]
    }
   ],
   "source": [
    "# Copy processed data files\n",
    "processed_files = list(PROCESSED_DATA_DIR.glob('*.csv'))\n",
    "\n",
    "print(f\"Archiving {len(processed_files)} processed data file(s)...\")\n",
    "\n",
    "for file_path in processed_files:\n",
    "    dest_path = ARCHIVE_SESSION_DIR / 'processed_data' / file_path.name\n",
    "    shutil.copy2(file_path, dest_path)\n",
    "    print(f\"  ✓ Archived: {file_path.name}\")\n",
    "\n",
    "print(\"\\nProcessed data archived successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d9b24",
   "metadata": {},
   "source": [
    "## 4. Archive Results and Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9d7fd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archiving 12 result file(s)...\n",
      "  ✓ Archived: fatigue_group_summary.csv\n",
      "  ✓ Archived: fatigue_pairwise_tests.csv\n",
      "  ✓ Archived: group_summary.csv\n",
      "  ✓ Archived: motility_metrics.csv\n",
      "  ✓ Archived: per_track_mean_speeds.csv\n",
      "  ✓ Archived: speed_group_summary.csv\n",
      "  ✓ Archived: speed_pairwise_tests.csv\n",
      "  ✓ Archived: straightness_group_summary.csv\n",
      "  ✓ Archived: straightness_pairwise_tests.csv\n",
      "  ✓ Archived: thrashing_frequency.csv\n",
      "  ✓ Archived: thrashing_group_summary.csv\n",
      "  ✓ Archived: thrashing_pairwise_tests.csv\n",
      "\n",
      "Archiving 1 JSON file(s)...\n",
      "  ✓ Archived: stats_summary.json\n",
      "\n",
      "Archiving 14 figure(s)...\n",
      "  ✓ Archived: fatigue_comparison.pdf\n",
      "  ✓ Archived: fatigue_comparison.png\n",
      "  ✓ Archived: mean_speed_comparison.pdf\n",
      "  ✓ Archived: mean_speed_comparison.png\n",
      "  ✓ Archived: straightness_comparison.pdf\n",
      "  ✓ Archived: straightness_comparison.png\n",
      "  ✓ Archived: summary_figure.pdf\n",
      "  ✓ Archived: summary_figure.png\n",
      "  ✓ Archived: thrashing_frequency_comparison.pdf\n",
      "  ✓ Archived: thrashing_frequency_comparison.png\n",
      "  ✓ Archived: track_trajectories_all.pdf\n",
      "  ✓ Archived: track_trajectories_all.png\n",
      "  ✓ Archived: track_trajectories_by_genotype.pdf\n",
      "  ✓ Archived: track_trajectories_by_genotype.png\n",
      "\n",
      "Results and figures archived successfully!\n"
     ]
    }
   ],
   "source": [
    "# Copy result CSV files\n",
    "result_files = [f for f in RESULTS_DIR.glob('*.csv') if f.is_file()]\n",
    "json_files = [f for f in RESULTS_DIR.glob('*.json') if f.is_file()]\n",
    "\n",
    "print(f\"Archiving {len(result_files)} result file(s)...\")\n",
    "for file_path in result_files:\n",
    "    dest_path = ARCHIVE_SESSION_DIR / 'results' / file_path.name\n",
    "    shutil.copy2(file_path, dest_path)\n",
    "    print(f\"  ✓ Archived: {file_path.name}\")\n",
    "\n",
    "print(f\"\\nArchiving {len(json_files)} JSON file(s)...\")\n",
    "for file_path in json_files:\n",
    "    dest_path = ARCHIVE_SESSION_DIR / 'results' / file_path.name\n",
    "    shutil.copy2(file_path, dest_path)\n",
    "    print(f\"  ✓ Archived: {file_path.name}\")\n",
    "\n",
    "# Copy figures\n",
    "if FIGURES_DIR.exists():\n",
    "    figure_files = list(FIGURES_DIR.glob('*'))\n",
    "    print(f\"\\nArchiving {len(figure_files)} figure(s)...\")\n",
    "    for file_path in figure_files:\n",
    "        if file_path.is_file():\n",
    "            dest_path = ARCHIVE_SESSION_DIR / 'figures' / file_path.name\n",
    "            shutil.copy2(file_path, dest_path)\n",
    "            print(f\"  ✓ Archived: {file_path.name}\")\n",
    "\n",
    "print(\"\\nResults and figures archived successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172b5a4",
   "metadata": {},
   "source": [
    "## 5. Collect and Archive Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "057cda06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 metadata file(s)\n",
      "  ✓ Archived: 260221_Wormlab_processed_N2_metadata_N2.yaml\n",
      "  ✓ Archived: 260221_Wormlab_processed_RK202_metadata_RK202.yaml\n",
      "  ✓ Archived: 260221_Wormlab_processed_RK203_metadata_RK203.yaml\n",
      "  ✓ Archived: 260221_Wormlab_processed_RK204_metadata_RK204.yaml\n",
      "  ✓ Archived: 260221_Wormlab_processed_RK205_metadata_RK205.yaml\n",
      "\n",
      "Metadata archived successfully!\n"
     ]
    }
   ],
   "source": [
    "# Find all metadata YAML files from raw data\n",
    "metadata_files = list(RAW_DATA_DIR.rglob('metadata_*.yaml'))\n",
    "\n",
    "print(f\"Found {len(metadata_files)} metadata file(s)\")\n",
    "\n",
    "# Copy metadata files to archive with organized structure\n",
    "for metadata_path in metadata_files:\n",
    "    # Create a readable name based on path\n",
    "    relative_path = metadata_path.relative_to(RAW_DATA_DIR)\n",
    "    # Replace path separators with underscores for flat structure\n",
    "    archive_name = str(relative_path).replace('\\\\', '_').replace('/', '_')\n",
    "    \n",
    "    dest_path = ARCHIVE_SESSION_DIR / 'metadata' / archive_name\n",
    "    shutil.copy2(metadata_path, dest_path)\n",
    "    print(f\"  ✓ Archived: {archive_name}\")\n",
    "\n",
    "print(\"\\nMetadata archived successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b17a5",
   "metadata": {},
   "source": [
    "## 6. Archive Raw Data and Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "380d157d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archiving 154 raw data file(s)...\n",
      "\n",
      "Raw data archived successfully!\n",
      "\n",
      "Archiving 4 notebook file(s)...\n",
      "  ✓ Archived: 01_Data_Wrangling.ipynb\n",
      "  ✓ Archived: 02_Analysis_and_Plotting.ipynb\n",
      "  ✓ Archived: 03_Archiving.ipynb\n",
      "  ✓ Archived: Motility_analysis.ipynb\n",
      "\n",
      "Notebooks archived successfully!\n"
     ]
    }
   ],
   "source": [
    "# Archive raw data (preserve folder structure)\n",
    "raw_files = [p for p in RAW_DATA_DIR.rglob('*') if p.is_file()]\n",
    "print(f\"Archiving {len(raw_files)} raw data file(s)...\")\n",
    "for file_path in raw_files:\n",
    "    dest_path = ARCHIVE_SESSION_DIR / 'raw_data' / file_path.relative_to(RAW_DATA_DIR)\n",
    "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copy2(file_path, dest_path)\n",
    "print(\"\\nRaw data archived successfully!\")\n",
    "\n",
    "# Archive current notebooks\n",
    "notebook_files = sorted(BASE_DIR.glob('*.ipynb'))\n",
    "print(f\"\\nArchiving {len(notebook_files)} notebook file(s)...\")\n",
    "for file_path in notebook_files:\n",
    "    dest_path = ARCHIVE_SESSION_DIR / 'notebooks' / file_path.name\n",
    "    shutil.copy2(file_path, dest_path)\n",
    "    print(f\"  ✓ Archived: {file_path.name}\")\n",
    "print(\"\\nNotebooks archived successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06daf281",
   "metadata": {},
   "source": [
    "## 7. Generate Analysis Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c11736",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strains' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generate summary report\u001b[39;00m\n\u001b[32m      2\u001b[39m report_content = [\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m# Motility Analysis Archive Summary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mArchive Date: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mArchive Location: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mARCHIVE_SESSION_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## Dataset Summary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Processed data files: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(PROCESSED_DATA_DIR.glob(\u001b[33m'\u001b[39m\u001b[33m*.csv\u001b[39m\u001b[33m'\u001b[39m)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Results files: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(RESULTS_DIR.glob(\u001b[33m'\u001b[39m\u001b[33m*.csv\u001b[39m\u001b[33m'\u001b[39m)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Figures: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(FIGURES_DIR.glob(\u001b[33m'\u001b[39m\u001b[33m*.png\u001b[39m\u001b[33m'\u001b[39m)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Metadata files: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m((ARCHIVE_SESSION_DIR\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m).glob(\u001b[33m'\u001b[39m\u001b[33m*.yaml\u001b[39m\u001b[33m'\u001b[39m)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Raw data files: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m([p\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m(ARCHIVE_SESSION_DIR\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mraw_data\u001b[39m\u001b[33m'\u001b[39m).rglob(\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mp.is_file()])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Notebooks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m((ARCHIVE_SESSION_DIR\u001b[38;5;250m \u001b[39m/\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnotebooks\u001b[39m\u001b[33m'\u001b[39m).glob(\u001b[33m'\u001b[39m\u001b[33m*.ipynb\u001b[39m\u001b[33m'\u001b[39m)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## Strains Analyzed\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Strains: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[43mstrains\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m## Processing Pipeline\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m1. Data Wrangling (01_Data_Wrangling.ipynb)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m2. Analysis and Plotting (02_Analysis_and_Plotting.ipynb)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m3. Archiving (03_Archiving.ipynb)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m ]\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Save report to file\u001b[39;00m\n\u001b[32m     26\u001b[39m report_path = ARCHIVE_SESSION_DIR / \u001b[33m'\u001b[39m\u001b[33manalysis_summary.md\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'strains' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate summary report\n",
    "strains = []\n",
    "if 'df_metrics' in globals() and isinstance(df_metrics, pd.DataFrame) and 'strain_genotype' in df_metrics.columns:\n",
    "    strains = sorted(df_metrics['strain_genotype'].dropna().unique().tolist())\n",
    "elif 'df_thrashing' in globals() and isinstance(df_thrashing, pd.DataFrame) and 'strain_genotype' in df_thrashing.columns:\n",
    "    strains = sorted(df_thrashing['strain_genotype'].dropna().unique().tolist())\n",
    "elif 'metadata_files' in globals():\n",
    "    strains = sorted({p.stem.replace('metadata_', '') for p in metadata_files})\n",
    "\n",
    "if not strains:\n",
    "    strains = [\"(unknown)\"]\n",
    "\n",
    "report_content = [\n",
    "    \"# Motility Analysis Archive Summary\",\n",
    "    f\"Archive Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"Archive Location: {ARCHIVE_SESSION_DIR}\",\n",
    "    \"\",\n",
    "    \"## Dataset Summary\",\n",
    "    f\"- Processed data files: {len(list(PROCESSED_DATA_DIR.glob('*.csv')))}\",\n",
    "    f\"- Results files: {len(list(RESULTS_DIR.glob('*.csv')))}\",\n",
    "    f\"- Figures: {len(list(FIGURES_DIR.glob('*.png')))}\",\n",
    "    f\"- Metadata files: {len(list((ARCHIVE_SESSION_DIR / 'metadata').glob('*.yaml')))}\",\n",
    "    f\"- Raw data files: {len([p for p in (ARCHIVE_SESSION_DIR / 'raw_data').rglob('*') if p.is_file()])}\",\n",
    "    f\"- Notebooks: {len(list((ARCHIVE_SESSION_DIR / 'notebooks').glob('*.ipynb')))}\",\n",
    "    \"\",\n",
    "    \"## Strains Analyzed\",\n",
    "    f\"- Strains: {', '.join(strains)}\",\n",
    "    \"\",\n",
    "    \"## Processing Pipeline\",\n",
    "    \"1. Data Wrangling (01_Data_Wrangling.ipynb)\",\n",
    "    \"2. Analysis and Plotting (02_Analysis_and_Plotting.ipynb)\",\n",
    "    \"3. Archiving (03_Archiving.ipynb)\",\n",
    "    \"\"\n",
    " ]\n",
    "\n",
    "# Save report to file\n",
    "report_path = ARCHIVE_SESSION_DIR / 'analysis_summary.md'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write('\\n'.join(report_content))\n",
    "\n",
    "print(f\"Summary report created: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe3190",
   "metadata": {},
   "source": [
    "## 8. Create Archive Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fe5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive manifest created:\n",
      "{\n",
      "  \"archive_info\": {\n",
      "    \"timestamp\": \"20260224_164017\",\n",
      "    \"date\": \"2026-02-24 16:41:26\",\n",
      "    \"archive_directory\": \"C:\\\\Users\\\\MBF\\\\Motility_analysis\\\\Data\\\\Archive\\\\archive_20260224_164017\"\n",
      "  },\n",
      "  \"data_summary\": {\n",
      "    \"total_tracks\": 107,\n",
      "    \"total_thrashing_tracks\": 107,\n",
      "    \"genotypes\": [\n",
      "      \"N2\",\n",
      "      \"RK202\",\n",
      "      \"RK203\",\n",
      "      \"RK204\",\n",
      "      \"RK205\"\n",
      "    ],\n",
      "    \"tracks_per_genotype\": {\n",
      "      \"N2\": 29,\n",
      "      \"RK202\": 20,\n",
      "      \"RK204\": 20,\n",
      "      \"RK205\": 20,\n",
      "      \"RK203\": 18\n",
      "    }\n",
      "  },\n",
      "  \"archived_files\": {\n",
      "    \"processed_data\": [\n",
      "      \"normalized_tracks.csv\",\n",
      "      \"thrashing_data.csv\",\n",
      "      \"track_metrics.csv\"\n",
      "    ],\n",
      "    \"results\": [\n",
      "      \"fatigue_group_summary.csv\",\n",
      "      \"fatigue_pairwise_tests.csv\",\n",
      "      \"group_summary.csv\",\n",
      "      \"motility_metrics.csv\",\n",
      "      \"per_track_mean_speeds.csv\",\n",
      "      \"speed_group_summary.csv\",\n",
      "      \"speed_pairwise_tests.csv\",\n",
      "      \"stats_summary.json\",\n",
      "      \"straightness_group_summary.csv\",\n",
      "      \"straightness_pairwise_tests.csv\",\n",
      "      \"thrashing_frequency.csv\",\n",
      "      \"thrashing_group_summary.csv\",\n",
      "      \"thrashing_pairwise_tests.csv\"\n",
      "    ],\n",
      "    \"figures\": [\n",
      "      \"fatigue_comparison.pdf\",\n",
      "      \"fatigue_comparison.png\",\n",
      "      \"mean_speed_comparison.pdf\",\n",
      "      \"mean_speed_comparison.png\",\n",
      "      \"straightness_comparison.pdf\",\n",
      "      \"straightness_comparison.png\",\n",
      "      \"summary_figure.pdf\",\n",
      "      \"summary_figure.png\",\n",
      "      \"thrashing_frequency_comparison.pdf\",\n",
      "      \"thrashing_frequency_comparison.png\",\n",
      "      \"track_trajectories_all.pdf\",\n",
      "      \"track_trajectories_all.png\",\n",
      "      \"track_trajectories_by_genotype.pdf\",\n",
      "      \"track_trajectories_by_genotype.png\"\n",
      "    ],\n",
      "    \"metadata\": [\n",
      "      \"260221_Wormlab_processed_N2_metadata_N2.yaml\",\n",
      "      \"260221_Wormlab_processed_RK202_metadata_RK202.yaml\",\n",
      "      \"260221_Wormlab_processed_RK203_metadata_RK203.yaml\",\n",
      "      \"260221_Wormlab_processed_RK204_metadata_RK204.yaml\",\n",
      "      \"260221_Wormlab_processed_RK205_metadata_RK205.yaml\"\n",
      "    ]\n",
      "  },\n",
      "  \"notebooks\": {\n",
      "    \"data_wrangling\": \"01_Data_Wrangling.ipynb\",\n",
      "    \"analysis_plotting\": \"02_Analysis_and_Plotting.ipynb\",\n",
      "    \"archiving\": \"03_Archiving.ipynb\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Manifest saved to: C:\\Users\\MBF\\Motility_analysis\\Data\\Archive\\archive_20260224_164017\\archive_manifest.json\n"
     ]
    }
   ],
   "source": [
    "# Create manifest of all files in archive\n",
    "manifest = {\n",
    "    'archive_date': datetime.now().isoformat(),\n",
    "    'archive_dir': str(ARCHIVE_SESSION_DIR),\n",
    "    'files': {\n",
    "        'processed_data': [],\n",
    "        'results': [],\n",
    "        'figures': [],\n",
    "        'metadata': [],\n",
    "        'raw_data': [],\n",
    "        'notebooks': []\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add files to manifest\n",
    "for file in (ARCHIVE_SESSION_DIR / 'processed_data').glob('*'):\n",
    "    manifest['files']['processed_data'].append(file.name)\n",
    "\n",
    "for file in (ARCHIVE_SESSION_DIR / 'results').glob('*'):\n",
    "    manifest['files']['results'].append(file.name)\n",
    "\n",
    "for file in (ARCHIVE_SESSION_DIR / 'figures').glob('*'):\n",
    "    manifest['files']['figures'].append(file.name)\n",
    "\n",
    "for file in (ARCHIVE_SESSION_DIR / 'metadata').glob('*'):\n",
    "    manifest['files']['metadata'].append(file.name)\n",
    "\n",
    "for file in (ARCHIVE_SESSION_DIR / 'raw_data').rglob('*'):\n",
    "    if file.is_file():\n",
    "        manifest['files']['raw_data'].append(str(file.relative_to(ARCHIVE_SESSION_DIR / 'raw_data')))\n",
    "\n",
    "for file in (ARCHIVE_SESSION_DIR / 'notebooks').glob('*.ipynb'):\n",
    "    manifest['files']['notebooks'].append(file.name)\n",
    "\n",
    "# Save manifest to JSON file\n",
    "manifest_path = ARCHIVE_SESSION_DIR / 'archive_manifest.json'\n",
    "with open(manifest_path, 'w') as f:\n",
    "    json.dump(manifest, f, indent=4)\n",
    "\n",
    "print(f\"Archive manifest created: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ecd8f",
   "metadata": {},
   "source": [
    "## 9. Create README for Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8a79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README created successfully!\n",
      "\n",
      "Saved to: C:\\Users\\MBF\\Motility_analysis\\Data\\Archive\\archive_20260224_164017\\README.md\n"
     ]
    }
   ],
   "source": [
    "# Create README file for the archive\n",
    "readme_content = [\n",
    "    \"# Motility Analysis Archive\",\n",
    "    f\"Archive Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    \"\",\n",
    "    \"## Directory Structure\",\n",
    "    \"\",\n",
    "    \"archive_{timestamp}/\",\n",
    "    \"├── processed_data/   # Processed CSV data files\",\n",
    "    \"├── results/          # Statistical results and summary tables\",\n",
    "    \"├── figures/          # Generated plots and figures\",\n",
    "    \"├── metadata/         # YAML metadata from raw data\",\n",
    "    \"├── raw_data/         # Raw data copied from Data/Raw\",\n",
    "    \"├── notebooks/        # Analysis notebooks\",\n",
    "    \"├── analysis_summary.md\",\n",
    "    \"├── archive_manifest.json\",\n",
    "    \"└── README.md\",\n",
    "    \"\",\n",
    "    \"## Files Included\",\n",
    "    \"\",\n",
    "    \"- Processed data files\",\n",
    "    \"- Statistical results\",\n",
    "    \"- Figures and plots\",\n",
    "    \"- Metadata files\",\n",
    "    \"- Raw data\",\n",
    "    \"- Analysis notebooks\",\n",
    "    \"- Archive summary report\",\n",
    "    \"- Archive manifest\",\n",
    "    \"\",\n",
    "    \"## Notes\",\n",
    "    \"\",\n",
    "    \"This archive contains all data and results from the motility analysis pipeline.\",\n",
    "    \"The raw data and notebooks are included to support full reproducibility.\"\n",
    "\n",
    "]\n",
    "\n",
    "# Save README to file\n",
    "readme_path = ARCHIVE_SESSION_DIR / 'README.md'\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write('\\n'.join(readme_content))\n",
    "\n",
    "print(f\"README created: {readme_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c5b1f",
   "metadata": {},
   "source": [
    "## 10. Optional: Create ZIP Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df546518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a compressed ZIP file of the entire archive\n",
    "zip_path = ARCHIVE_DIR / f'archive_{TIMESTAMP}.zip'\n",
    "\n",
    "print(f\"Creating ZIP archive: {zip_path.name}\")\n",
    "print(\"This may take a moment...\\n\")\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file_path in ARCHIVE_SESSION_DIR.rglob('*'):\n",
    "        if file_path.is_file():\n",
    "            arc_name = file_path.relative_to(ARCHIVE_SESSION_DIR.parent)\n",
    "            zipf.write(file_path, arc_name)\n",
    "            print(f\"  Added: {arc_name}\")\n",
    "\n",
    "zip_size_mb = zip_path.stat().st_size / (1024 * 1024)\n",
    "print(f\"\\nZIP archive created successfully!\")\n",
    "print(f\"Size: {zip_size_mb:.2f} MB\")\n",
    "print(f\"Location: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205b7f6",
   "metadata": {},
   "source": [
    "## 11. Clean Up Old Archives (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a135e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all archive directories\n",
    "archive_dirs = sorted([d for d in ARCHIVE_DIR.iterdir() if d.is_dir() and d.name.startswith('archive_')])\n",
    "\n",
    "print(f\"Found {len(archive_dirs)} archive directory/directories:\")\n",
    "for archive_dir in archive_dirs:\n",
    "    creation_time = datetime.fromtimestamp(archive_dir.stat().st_ctime)\n",
    "    print(f\"  - {archive_dir.name} (created: {creation_time.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# Optional: Delete archives older than X days (UNCOMMENT TO ENABLE)\n",
    "# DAYS_TO_KEEP = 30\n",
    "# cutoff_date = datetime.now() - pd.Timedelta(days=DAYS_TO_KEEP)\n",
    "# \n",
    "# for archive_dir in archive_dirs:\n",
    "#     creation_time = datetime.fromtimestamp(archive_dir.stat().st_ctime)\n",
    "#     if creation_time < cutoff_date and archive_dir.name != f'archive_{TIMESTAMP}':\n",
    "#         print(f\"Deleting old archive: {archive_dir.name}\")\n",
    "#         shutil.rmtree(archive_dir)\n",
    "\n",
    "print(\"\\nNote: Automatic cleanup is disabled by default. Edit this cell to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaf3068",
   "metadata": {},
   "source": [
    "## 12. Archive Summary and Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8fb278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ARCHIVING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Archive ID: 20260224_164017\n",
      "Archive Location: C:\\Users\\MBF\\Motility_analysis\\Data\\Archive\\archive_20260224_164017\n",
      "\n",
      "Archived Contents:\n",
      "  - Processed data files: 3\n",
      "  - Result files: 13\n",
      "  - Figure files: 14\n",
      "  - Metadata files: 5\n",
      "\n",
      "Documentation:\n",
      "  ✓ README.md\n",
      "  ✓ ANALYSIS_SUMMARY_REPORT.txt\n",
      "  ✓ archive_manifest.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'zip_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ ANALYSIS_SUMMARY_REPORT.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ archive_manifest.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mzip_path\u001b[49m.exists():\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCompressed Archive:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_path.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_size_mb\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m MB)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'zip_path' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ARCHIVING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nArchive ID: {TIMESTAMP}\")\n",
    "print(f\"Archive Location: {ARCHIVE_SESSION_DIR}\")\n",
    "\n",
    "print(\"\\nArchived Contents:\")\n",
    "print(f\"  - Processed data files: {len(list((ARCHIVE_SESSION_DIR / 'processed_data').glob('*')))}\")\n",
    "print(f\"  - Result files: {len(list((ARCHIVE_SESSION_DIR / 'results').glob('*')))}\")\n",
    "print(f\"  - Figure files: {len(list((ARCHIVE_SESSION_DIR / 'figures').glob('*')))}\")\n",
    "print(f\"  - Metadata files: {len(list((ARCHIVE_SESSION_DIR / 'metadata').glob('*')))}\")\n",
    "\n",
    "print(\"\\nDocumentation:\")\n",
    "print(f\"  ✓ README.md\")\n",
    "print(f\"  ✓ ANALYSIS_SUMMARY_REPORT.txt\")\n",
    "print(f\"  ✓ archive_manifest.json\")\n",
    "\n",
    "if zip_path.exists():\n",
    "    print(f\"\\nCompressed Archive:\")\n",
    "    print(f\"  ✓ {zip_path.name} ({zip_size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All analysis results have been archived and documented.\")\n",
    "print(\"The archive is ready for long-term storage or sharing.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wormlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
